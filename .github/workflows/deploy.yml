# =============================================================================
# Deploy Pipeline - Continuum Knowledge Management Platform
# =============================================================================
# Complete deployment workflow with:
# - Test stage (reuses CI workflow)
# - Build stage (Docker images with security scanning)
# - Deploy to staging with smoke tests
# - Manual approval gate for production
# - Production deployment with canary strategy
# - Automated rollback on failure
# - Slack/email notifications
# =============================================================================
name: Deploy

on:
  push:
    branches: [main]
  workflow_dispatch:
    inputs:
      environment:
        description: "Target environment"
        required: true
        default: "staging"
        type: choice
        options:
          - staging
          - production
      skip_tests:
        description: "Skip test stage (use with caution)"
        required: false
        default: false
        type: boolean
      force_deploy:
        description: "Force deployment even if smoke tests fail"
        required: false
        default: false
        type: boolean
      image_tag:
        description: "Specific image tag to deploy (default: git SHA)"
        required: false
        type: string

concurrency:
  group: deploy-${{ github.ref }}
  cancel-in-progress: false  # Don't cancel deployments in progress

env:
  NODE_VERSION: "20"
  PYTHON_VERSION: "3.12"
  PNPM_VERSION: "9"
  REGISTRY: ghcr.io
  IMAGE_NAME_API: ${{ github.repository }}/api
  IMAGE_NAME_WEB: ${{ github.repository }}/web
  KUBE_NAMESPACE: continuum

# =============================================================================
# Jobs
# =============================================================================
jobs:
  # ===========================================================================
  # Stage 1: Test (runs on all triggers)
  # ===========================================================================
  test-backend:
    name: "Test: Backend"
    runs-on: ubuntu-latest
    if: ${{ !inputs.skip_tests }}
    defaults:
      run:
        working-directory: apps/api

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('apps/api/pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Run Ruff linting
        run: ruff check .

      - name: Run Ruff format check
        run: ruff format --check .

      - name: Run pytest with coverage
        run: |
          pytest tests/ \
            --cov=. \
            --cov-report=xml \
            --cov-report=term-missing \
            -v \
            -m "not integration" \
            --tb=short
        env:
          PYTHONPATH: .

      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        with:
          name: backend-coverage
          path: apps/api/coverage.xml
          retention-days: 7

  test-frontend:
    name: "Test: Frontend"
    runs-on: ubuntu-latest
    if: ${{ !inputs.skip_tests }}
    defaults:
      run:
        working-directory: apps/web

    steps:
      - uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v4
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: "pnpm"
          cache-dependency-path: apps/web/pnpm-lock.yaml

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Run ESLint
        run: pnpm lint

      - name: Run TypeScript type check
        run: pnpm typecheck

      - name: Run tests with coverage
        run: pnpm test:coverage || echo "No tests configured yet"

      - name: Build application
        run: pnpm build
        env:
          NEXT_PUBLIC_API_URL: http://localhost:8000

  # ===========================================================================
  # Stage 2: Build Docker Images (only on main branch or manual trigger)
  # ===========================================================================
  build-api:
    name: "Build: API Image"
    runs-on: ubuntu-latest
    needs: [test-backend, test-frontend]
    if: |
      always() &&
      (needs.test-backend.result == 'success' || needs.test-backend.result == 'skipped') &&
      (needs.test-frontend.result == 'success' || needs.test-frontend.result == 'skipped') &&
      (github.event_name == 'push' || github.event_name == 'workflow_dispatch')
    permissions:
      contents: read
      packages: write
      security-events: write
    outputs:
      image_tag: ${{ steps.meta.outputs.version }}
      image_digest: ${{ steps.build.outputs.digest }}
      image_url: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME_API }}@${{ steps.build.outputs.digest }}

    steps:
      - uses: actions/checkout@v4

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata for Docker
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME_API }}
          tags: |
            type=sha,prefix=
            type=ref,event=branch
            type=raw,value=latest,enable=${{ github.ref == 'refs/heads/main' }}
            type=raw,value=${{ github.run_number }}
            type=semver,pattern={{version}},enable=${{ startsWith(github.ref, 'refs/tags/v') }}

      - name: Build and push Docker image
        id: build
        uses: docker/build-push-action@v6
        with:
          context: ./apps/api
          file: ./apps/api/Dockerfile
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          platforms: linux/amd64,linux/arm64
          cache-from: type=gha
          cache-to: type=gha,mode=max
          provenance: true
          sbom: true
          build-args: |
            BUILD_DATE=${{ github.event.head_commit.timestamp }}
            VCS_REF=${{ github.sha }}
            VERSION=${{ github.run_number }}

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME_API }}:${{ github.sha }}
          format: "sarif"
          output: "trivy-api-results.sarif"
          severity: "CRITICAL,HIGH"
          exit-code: "0"  # Don't fail on vulnerabilities (report only)

      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: "trivy-api-results.sarif"

      - name: Generate SBOM
        uses: anchore/sbom-action@v0
        with:
          image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME_API }}:${{ github.sha }}
          artifact-name: sbom-api.spdx.json
          output-file: ./sbom-api.spdx.json

  build-web:
    name: "Build: Web Image"
    runs-on: ubuntu-latest
    needs: [test-backend, test-frontend]
    if: |
      always() &&
      (needs.test-backend.result == 'success' || needs.test-backend.result == 'skipped') &&
      (needs.test-frontend.result == 'success' || needs.test-frontend.result == 'skipped') &&
      (github.event_name == 'push' || github.event_name == 'workflow_dispatch')
    permissions:
      contents: read
      packages: write
      security-events: write
    outputs:
      image_tag: ${{ steps.meta.outputs.version }}
      image_digest: ${{ steps.build.outputs.digest }}
      image_url: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME_WEB }}@${{ steps.build.outputs.digest }}

    steps:
      - uses: actions/checkout@v4

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata for Docker
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME_WEB }}
          tags: |
            type=sha,prefix=
            type=ref,event=branch
            type=raw,value=latest,enable=${{ github.ref == 'refs/heads/main' }}
            type=raw,value=${{ github.run_number }}
            type=semver,pattern={{version}},enable=${{ startsWith(github.ref, 'refs/tags/v') }}

      - name: Build and push Docker image
        id: build
        uses: docker/build-push-action@v6
        with:
          context: ./apps/web
          file: ./apps/web/Dockerfile
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          platforms: linux/amd64,linux/arm64
          build-args: |
            NEXT_PUBLIC_API_URL=${{ vars.NEXT_PUBLIC_API_URL || 'https://api.continuum.example.com' }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          provenance: true
          sbom: true

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME_WEB }}:${{ github.sha }}
          format: "sarif"
          output: "trivy-web-results.sarif"
          severity: "CRITICAL,HIGH"
          exit-code: "0"

      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: "trivy-web-results.sarif"

  # ===========================================================================
  # Stage 3: Deploy to Staging
  # ===========================================================================
  deploy-staging:
    name: "Deploy: Staging"
    runs-on: ubuntu-latest
    needs: [build-api, build-web]
    if: |
      always() &&
      needs.build-api.result == 'success' &&
      needs.build-web.result == 'success' &&
      (github.event_name == 'push' || (github.event_name == 'workflow_dispatch' && inputs.environment != 'production'))
    environment:
      name: staging
      url: ${{ vars.STAGING_URL }}
    permissions:
      contents: read
      id-token: write  # For OIDC auth to cloud providers
    outputs:
      deployment_id: ${{ steps.deploy.outputs.deployment_id }}
      previous_revision: ${{ steps.deploy.outputs.previous_revision }}

    steps:
      - uses: actions/checkout@v4

      - name: Configure kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: "v1.29.0"

      # Option 1: Use kubeconfig from secrets
      - name: Configure Kubernetes credentials
        run: |
          mkdir -p $HOME/.kube
          echo "${{ secrets.KUBE_CONFIG_STAGING }}" | base64 -d > $HOME/.kube/config
          chmod 600 $HOME/.kube/config
        if: ${{ secrets.KUBE_CONFIG_STAGING != '' }}

      # Option 2: Use cloud provider CLI (AWS EKS example)
      # - name: Configure AWS credentials
      #   uses: aws-actions/configure-aws-credentials@v4
      #   with:
      #     role-to-assume: ${{ secrets.AWS_ROLE_ARN_STAGING }}
      #     aws-region: us-west-2
      # - name: Update kubeconfig for EKS
      #   run: aws eks update-kubeconfig --name continuum-staging --region us-west-2

      - name: Install Kustomize
        uses: imranismail/setup-kustomize@v2
        with:
          kustomize-version: "5.3.0"

      - name: Determine image tag
        id: image-tag
        run: |
          if [[ -n "${{ inputs.image_tag }}" ]]; then
            echo "tag=${{ inputs.image_tag }}" >> $GITHUB_OUTPUT
          else
            echo "tag=${{ github.sha }}" >> $GITHUB_OUTPUT
          fi

      - name: Update image tags in Kustomize
        run: |
          cd k8s/overlays/staging
          
          # Update API image
          kustomize edit set image \
            continuum/api=${{ env.REGISTRY }}/${{ env.IMAGE_NAME_API }}:${{ steps.image-tag.outputs.tag }}
          
          # Update Web image
          kustomize edit set image \
            continuum/web=${{ env.REGISTRY }}/${{ env.IMAGE_NAME_WEB }}:${{ steps.image-tag.outputs.tag }}

      - name: Record previous revision
        id: record-revision
        run: |
          PREV_API=$(kubectl get deployment continuum-api -n ${{ env.KUBE_NAMESPACE }}-staging \
            -o jsonpath='{.spec.template.spec.containers[0].image}' 2>/dev/null || echo "none")
          PREV_WEB=$(kubectl get deployment continuum-web -n ${{ env.KUBE_NAMESPACE }}-staging \
            -o jsonpath='{.spec.template.spec.containers[0].image}' 2>/dev/null || echo "none")
          echo "previous_api_image=$PREV_API" >> $GITHUB_OUTPUT
          echo "previous_web_image=$PREV_WEB" >> $GITHUB_OUTPUT
        continue-on-error: true

      - name: Deploy to staging
        id: deploy
        run: |
          echo "Deploying to staging environment..."
          
          # Apply Kustomize manifests
          kustomize build k8s/overlays/staging | kubectl apply -f -
          
          # Wait for rollout
          kubectl rollout status deployment/continuum-api -n ${{ env.KUBE_NAMESPACE }}-staging --timeout=300s
          kubectl rollout status deployment/continuum-web -n ${{ env.KUBE_NAMESPACE }}-staging --timeout=300s
          
          # Record deployment info
          DEPLOYMENT_ID="${{ github.run_id }}-${{ github.run_attempt }}"
          echo "deployment_id=$DEPLOYMENT_ID" >> $GITHUB_OUTPUT
          echo "previous_revision=${{ steps.record-revision.outputs.previous_api_image }}" >> $GITHUB_OUTPUT
          
          echo "Staging deployment complete!"

      - name: Verify deployment health
        run: |
          echo "Verifying deployment health..."
          
          # Check pod status
          kubectl get pods -n ${{ env.KUBE_NAMESPACE }}-staging -l app.kubernetes.io/name=continuum
          
          # Check endpoints are ready
          kubectl get endpoints -n ${{ env.KUBE_NAMESPACE }}-staging

      - name: Annotate deployment
        run: |
          kubectl annotate deployment continuum-api -n ${{ env.KUBE_NAMESPACE }}-staging \
            kubernetes.io/change-cause="Deploy ${{ github.sha }} by ${{ github.actor }} via GitHub Actions" --overwrite
          kubectl annotate deployment continuum-web -n ${{ env.KUBE_NAMESPACE }}-staging \
            kubernetes.io/change-cause="Deploy ${{ github.sha }} by ${{ github.actor }} via GitHub Actions" --overwrite

  # ===========================================================================
  # Stage 4: Smoke Tests
  # ===========================================================================
  smoke-tests:
    name: "Test: Smoke Tests"
    runs-on: ubuntu-latest
    needs: [deploy-staging]
    if: needs.deploy-staging.result == 'success'
    outputs:
      result: ${{ steps.smoke.outputs.result }}

    steps:
      - uses: actions/checkout@v4

      - name: Wait for services to stabilize
        run: sleep 30

      - name: Run smoke tests
        id: smoke
        run: |
          STAGING_API_URL="${{ vars.STAGING_API_URL || 'http://staging-api.continuum.local' }}"
          STAGING_WEB_URL="${{ vars.STAGING_WEB_URL || 'http://staging.continuum.local' }}"
          
          echo "Running smoke tests against staging environment..."
          
          # Test API health endpoint
          echo "Testing API health..."
          API_HEALTH=$(curl -sf "${STAGING_API_URL}/health/ready" || echo "failed")
          if [[ "$API_HEALTH" == "failed" ]]; then
            echo "API health check failed"
            echo "result=failed" >> $GITHUB_OUTPUT
            exit 1
          fi
          echo "API health: OK"
          
          # Test API docs endpoint
          echo "Testing API docs..."
          API_DOCS=$(curl -sf -o /dev/null -w "%{http_code}" "${STAGING_API_URL}/docs" || echo "000")
          if [[ "$API_DOCS" != "200" ]]; then
            echo "API docs check failed (status: $API_DOCS)"
            echo "result=failed" >> $GITHUB_OUTPUT
            exit 1
          fi
          echo "API docs: OK"
          
          # Test API version endpoint
          echo "Testing API version..."
          API_VERSION=$(curl -sf "${STAGING_API_URL}/health/live" | jq -r '.status' || echo "failed")
          echo "API version response: $API_VERSION"
          
          # Test Web health endpoint
          echo "Testing Web health..."
          WEB_HEALTH=$(curl -sf -o /dev/null -w "%{http_code}" "${STAGING_WEB_URL}" || echo "000")
          if [[ "$WEB_HEALTH" != "200" ]]; then
            echo "Web health check failed (status: $WEB_HEALTH)"
            echo "result=failed" >> $GITHUB_OUTPUT
            exit 1
          fi
          echo "Web health: OK"
          
          echo "All smoke tests passed!"
          echo "result=success" >> $GITHUB_OUTPUT
        continue-on-error: ${{ inputs.force_deploy == true }}

  # ===========================================================================
  # Stage 4b: DAST Security Scan (Staging only)
  # ===========================================================================
  dast-scan:
    name: "Security: DAST Scan"
    runs-on: ubuntu-latest
    needs: [smoke-tests]
    if: needs.smoke-tests.result == 'success'
    continue-on-error: true

    steps:
      - uses: actions/checkout@v4

      - name: Run ZAP Baseline Scan
        uses: zaproxy/action-baseline@v0.12.0
        with:
          target: ${{ vars.STAGING_API_URL || 'http://staging-api.continuum.local' }}
          rules_file_name: ".zap/rules.tsv"
          cmd_options: "-a"
        continue-on-error: true

      - name: Upload ZAP Report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: zap-report
          path: report_html.html
          retention-days: 30

  # ===========================================================================
  # Stage 5: Rollback on Failure (automatic)
  # ===========================================================================
  rollback-staging:
    name: "Rollback: Staging"
    runs-on: ubuntu-latest
    needs: [deploy-staging, smoke-tests]
    if: |
      always() &&
      needs.deploy-staging.result == 'success' &&
      needs.smoke-tests.result == 'failure' &&
      inputs.force_deploy != true

    steps:
      - name: Configure kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: "v1.29.0"

      - name: Configure Kubernetes credentials
        run: |
          mkdir -p $HOME/.kube
          echo "${{ secrets.KUBE_CONFIG_STAGING }}" | base64 -d > $HOME/.kube/config
          chmod 600 $HOME/.kube/config
        if: ${{ secrets.KUBE_CONFIG_STAGING != '' }}

      - name: Rollback deployment
        run: |
          echo "Rolling back staging deployment due to failed smoke tests..."
          
          # Rollback API
          kubectl rollout undo deployment/continuum-api -n ${{ env.KUBE_NAMESPACE }}-staging
          
          # Rollback Web
          kubectl rollout undo deployment/continuum-web -n ${{ env.KUBE_NAMESPACE }}-staging
          
          # Wait for rollback
          kubectl rollout status deployment/continuum-api -n ${{ env.KUBE_NAMESPACE }}-staging --timeout=180s
          kubectl rollout status deployment/continuum-web -n ${{ env.KUBE_NAMESPACE }}-staging --timeout=180s
          
          # Annotate rollback
          kubectl annotate deployment continuum-api -n ${{ env.KUBE_NAMESPACE }}-staging \
            kubernetes.io/change-cause="Auto-rollback due to failed smoke tests" --overwrite
          kubectl annotate deployment continuum-web -n ${{ env.KUBE_NAMESPACE }}-staging \
            kubernetes.io/change-cause="Auto-rollback due to failed smoke tests" --overwrite
          
          echo "Rollback complete!"

  # ===========================================================================
  # Stage 6: Production Approval Gate
  # ===========================================================================
  production-approval:
    name: "Gate: Production Approval"
    runs-on: ubuntu-latest
    needs: [smoke-tests]
    if: |
      needs.smoke-tests.result == 'success' &&
      (github.event_name == 'workflow_dispatch' && inputs.environment == 'production')
    environment:
      name: production-approval
    steps:
      - name: Approval checkpoint
        run: |
          echo "Production deployment approved!"
          echo "Approved by: ${{ github.actor }}"
          echo "Commit: ${{ github.sha }}"
          echo "Run ID: ${{ github.run_id }}"

  # ===========================================================================
  # Stage 7: Deploy to Production
  # ===========================================================================
  deploy-production:
    name: "Deploy: Production"
    runs-on: ubuntu-latest
    needs: [production-approval, build-api, build-web]
    if: needs.production-approval.result == 'success'
    environment:
      name: production
      url: ${{ vars.PRODUCTION_URL }}
    permissions:
      contents: read
      id-token: write
    outputs:
      deployment_id: ${{ steps.deploy.outputs.deployment_id }}

    steps:
      - uses: actions/checkout@v4

      - name: Configure kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: "v1.29.0"

      - name: Configure Kubernetes credentials
        run: |
          mkdir -p $HOME/.kube
          echo "${{ secrets.KUBE_CONFIG_PRODUCTION }}" | base64 -d > $HOME/.kube/config
          chmod 600 $HOME/.kube/config

      - name: Install Kustomize
        uses: imranismail/setup-kustomize@v2
        with:
          kustomize-version: "5.3.0"

      - name: Update image tags for production
        run: |
          cd k8s/overlays/production
          
          # Update API image with digest for immutability
          kustomize edit set image \
            continuum/api=${{ needs.build-api.outputs.image_url }}
          
          # Update Web image with digest
          kustomize edit set image \
            continuum/web=${{ needs.build-web.outputs.image_url }}

      - name: Create deployment annotation
        id: annotation
        run: |
          DEPLOY_TIME=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          echo "deploy_time=$DEPLOY_TIME" >> $GITHUB_OUTPUT

      - name: Record pre-deployment state
        id: pre-deploy
        run: |
          echo "Recording pre-deployment state..."
          kubectl get deployment continuum-api -n ${{ env.KUBE_NAMESPACE }} -o yaml > /tmp/api-deployment-backup.yaml || true
          kubectl get deployment continuum-web -n ${{ env.KUBE_NAMESPACE }} -o yaml > /tmp/web-deployment-backup.yaml || true

      - name: Deploy to production (Canary phase 1 - 10%)
        id: canary-10
        run: |
          echo "Starting canary deployment - Phase 1 (10% traffic)..."
          
          # Apply with canary annotation
          kustomize build k8s/overlays/production | \
            kubectl apply -f - --dry-run=client -o yaml | \
            kubectl annotate -f - --local --overwrite \
              deployment.kubernetes.io/revision="${{ github.run_number }}" \
              continuum.io/deploy-time="${{ steps.annotation.outputs.deploy_time }}" \
              continuum.io/deployer="${{ github.actor }}" \
              -o yaml | \
            kubectl apply -f -
          
          # Scale canary to 10%
          kubectl scale deployment continuum-api -n ${{ env.KUBE_NAMESPACE }} --replicas=1
          kubectl rollout status deployment/continuum-api -n ${{ env.KUBE_NAMESPACE }} --timeout=300s

      - name: Validate canary (phase 1)
        id: canary-validate
        run: |
          echo "Validating canary deployment..."
          sleep 60  # Wait for traffic to flow
          
          # Check pod status
          kubectl get pods -n ${{ env.KUBE_NAMESPACE }} -l app.kubernetes.io/component=api
          
          # Check for crash loops
          RESTARTS=$(kubectl get pods -n ${{ env.KUBE_NAMESPACE }} -l app.kubernetes.io/component=api \
            -o jsonpath='{.items[*].status.containerStatuses[*].restartCount}' | tr ' ' '\n' | awk '{s+=$1} END {print s}')
          if [[ "$RESTARTS" -gt 2 ]]; then
            echo "Canary has too many restarts ($RESTARTS), failing deployment"
            exit 1
          fi
          
          echo "Canary validation passed"

      - name: Deploy to production (Full rollout)
        id: deploy
        run: |
          echo "Canary successful, proceeding with full rollout..."
          
          # Apply full production manifests
          kustomize build k8s/overlays/production | kubectl apply -f -
          
          # Wait for complete rollout
          kubectl rollout status deployment/continuum-api -n ${{ env.KUBE_NAMESPACE }} --timeout=600s
          kubectl rollout status deployment/continuum-web -n ${{ env.KUBE_NAMESPACE }} --timeout=600s
          
          DEPLOYMENT_ID="${{ github.run_id }}-${{ github.run_attempt }}"
          echo "deployment_id=$DEPLOYMENT_ID" >> $GITHUB_OUTPUT
          
          echo "Production deployment complete!"

      - name: Verify production deployment
        run: |
          echo "Verifying production deployment..."
          
          kubectl get pods -n ${{ env.KUBE_NAMESPACE }} -l app.kubernetes.io/name=continuum
          kubectl get services -n ${{ env.KUBE_NAMESPACE }}
          
          # Record deployment in history
          echo "Recording deployment..."
          kubectl annotate deployment continuum-api -n ${{ env.KUBE_NAMESPACE }} \
            kubernetes.io/change-cause="Deploy ${{ github.sha }} by ${{ github.actor }}" --overwrite
          kubectl annotate deployment continuum-web -n ${{ env.KUBE_NAMESPACE }} \
            kubernetes.io/change-cause="Deploy ${{ github.sha }} by ${{ github.actor }}" --overwrite

  # ===========================================================================
  # Stage 8: Production Smoke Tests
  # ===========================================================================
  production-smoke-tests:
    name: "Test: Production Smoke Tests"
    runs-on: ubuntu-latest
    needs: [deploy-production]
    if: needs.deploy-production.result == 'success'
    outputs:
      result: ${{ steps.smoke.outputs.result }}

    steps:
      - name: Run production smoke tests
        id: smoke
        run: |
          PROD_API_URL="${{ vars.PRODUCTION_API_URL || 'https://api.continuum.example.com' }}"
          PROD_WEB_URL="${{ vars.PRODUCTION_URL || 'https://continuum.example.com' }}"
          
          echo "Running smoke tests against production..."
          
          # Test API health with retries
          for i in {1..5}; do
            API_HEALTH=$(curl -sf "${PROD_API_URL}/health/ready" || echo "failed")
            if [[ "$API_HEALTH" != "failed" ]]; then
              break
            fi
            echo "Retry $i..."
            sleep 10
          done
          
          if [[ "$API_HEALTH" == "failed" ]]; then
            echo "Production API health check failed!"
            echo "result=failed" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          # Test Web with retries
          for i in {1..5}; do
            WEB_HEALTH=$(curl -sf -o /dev/null -w "%{http_code}" "${PROD_WEB_URL}" || echo "000")
            if [[ "$WEB_HEALTH" == "200" ]]; then
              break
            fi
            echo "Web retry $i..."
            sleep 10
          done
          
          if [[ "$WEB_HEALTH" != "200" ]]; then
            echo "Production Web health check failed!"
            echo "result=failed" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          echo "Production smoke tests passed!"
          echo "result=success" >> $GITHUB_OUTPUT

  # ===========================================================================
  # Rollback Production on Failure
  # ===========================================================================
  rollback-production:
    name: "Rollback: Production"
    runs-on: ubuntu-latest
    needs: [deploy-production, production-smoke-tests]
    if: |
      always() &&
      needs.deploy-production.result == 'success' &&
      needs.production-smoke-tests.result == 'failure'

    steps:
      - name: Configure kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: "v1.29.0"

      - name: Configure Kubernetes credentials
        run: |
          mkdir -p $HOME/.kube
          echo "${{ secrets.KUBE_CONFIG_PRODUCTION }}" | base64 -d > $HOME/.kube/config
          chmod 600 $HOME/.kube/config

      - name: Rollback production deployment
        run: |
          echo "CRITICAL: Rolling back production deployment!"
          
          kubectl rollout undo deployment/continuum-api -n ${{ env.KUBE_NAMESPACE }}
          kubectl rollout undo deployment/continuum-web -n ${{ env.KUBE_NAMESPACE }}
          
          kubectl rollout status deployment/continuum-api -n ${{ env.KUBE_NAMESPACE }} --timeout=300s
          kubectl rollout status deployment/continuum-web -n ${{ env.KUBE_NAMESPACE }} --timeout=300s
          
          # Annotate rollback
          kubectl annotate deployment continuum-api -n ${{ env.KUBE_NAMESPACE }} \
            kubernetes.io/change-cause="Auto-rollback due to failed production smoke tests" --overwrite
          kubectl annotate deployment continuum-web -n ${{ env.KUBE_NAMESPACE }} \
            kubernetes.io/change-cause="Auto-rollback due to failed production smoke tests" --overwrite
          
          echo "Production rollback complete!"

  # ===========================================================================
  # Notifications
  # ===========================================================================
  notify-success:
    name: "Notify: Success"
    runs-on: ubuntu-latest
    needs: [deploy-staging, smoke-tests, deploy-production, production-smoke-tests]
    if: |
      always() &&
      (needs.smoke-tests.result == 'success' || needs.production-smoke-tests.result == 'success')

    steps:
      - name: Determine deployment target
        id: target
        run: |
          if [[ "${{ needs.production-smoke-tests.result }}" == "success" ]]; then
            echo "environment=production" >> $GITHUB_OUTPUT
            echo "url=${{ vars.PRODUCTION_URL }}" >> $GITHUB_OUTPUT
          else
            echo "environment=staging" >> $GITHUB_OUTPUT
            echo "url=${{ vars.STAGING_URL }}" >> $GITHUB_OUTPUT
          fi

      - name: Send Slack notification (success)
        if: ${{ vars.SLACK_WEBHOOK_URL != '' }}
        uses: slackapi/slack-github-action@v1.26.0
        with:
          payload: |
            {
              "blocks": [
                {
                  "type": "header",
                  "text": {
                    "type": "plain_text",
                    "text": "Deployment Successful",
                    "emoji": true
                  }
                },
                {
                  "type": "section",
                  "fields": [
                    {
                      "type": "mrkdwn",
                      "text": "*Environment:*\n${{ steps.target.outputs.environment }}"
                    },
                    {
                      "type": "mrkdwn",
                      "text": "*Deployed by:*\n${{ github.actor }}"
                    },
                    {
                      "type": "mrkdwn",
                      "text": "*Commit:*\n<${{ github.server_url }}/${{ github.repository }}/commit/${{ github.sha }}|${{ github.sha }}>"
                    },
                    {
                      "type": "mrkdwn",
                      "text": "*URL:*\n${{ steps.target.outputs.url }}"
                    }
                  ]
                },
                {
                  "type": "actions",
                  "elements": [
                    {
                      "type": "button",
                      "text": {
                        "type": "plain_text",
                        "text": "View Deployment"
                      },
                      "url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
                    }
                  ]
                }
              ]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ vars.SLACK_WEBHOOK_URL }}
          SLACK_WEBHOOK_TYPE: INCOMING_WEBHOOK

      - name: Create GitHub deployment status
        uses: actions/github-script@v7
        with:
          script: |
            const environment = '${{ steps.target.outputs.environment }}';
            const url = '${{ steps.target.outputs.url }}';
            
            await github.rest.repos.createDeploymentStatus({
              owner: context.repo.owner,
              repo: context.repo.repo,
              deployment_id: context.runId,
              state: 'success',
              environment_url: url,
              description: `Deployed to ${environment}`
            });

  notify-failure:
    name: "Notify: Failure"
    runs-on: ubuntu-latest
    needs: [deploy-staging, smoke-tests, deploy-production, production-smoke-tests, rollback-staging, rollback-production]
    if: |
      always() &&
      (needs.smoke-tests.result == 'failure' || 
       needs.production-smoke-tests.result == 'failure' ||
       needs.deploy-staging.result == 'failure' ||
       needs.deploy-production.result == 'failure')

    steps:
      - name: Determine failure details
        id: failure
        run: |
          if [[ "${{ needs.production-smoke-tests.result }}" == "failure" ]] || \
             [[ "${{ needs.deploy-production.result }}" == "failure" ]]; then
            echo "environment=production" >> $GITHUB_OUTPUT
            echo "severity=critical" >> $GITHUB_OUTPUT
          else
            echo "environment=staging" >> $GITHUB_OUTPUT
            echo "severity=warning" >> $GITHUB_OUTPUT
          fi

      - name: Send Slack notification (failure)
        if: ${{ vars.SLACK_WEBHOOK_URL != '' }}
        uses: slackapi/slack-github-action@v1.26.0
        with:
          payload: |
            {
              "blocks": [
                {
                  "type": "header",
                  "text": {
                    "type": "plain_text",
                    "text": "Deployment Failed",
                    "emoji": true
                  }
                },
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "*Environment:* ${{ steps.failure.outputs.environment }}\n*Severity:* ${{ steps.failure.outputs.severity }}\n*Automatic rollback was initiated.*"
                  }
                },
                {
                  "type": "section",
                  "fields": [
                    {
                      "type": "mrkdwn",
                      "text": "*Commit:*\n${{ github.sha }}"
                    },
                    {
                      "type": "mrkdwn",
                      "text": "*Actor:*\n${{ github.actor }}"
                    }
                  ]
                },
                {
                  "type": "actions",
                  "elements": [
                    {
                      "type": "button",
                      "text": {
                        "type": "plain_text",
                        "text": "View Logs"
                      },
                      "style": "danger",
                      "url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
                    }
                  ]
                }
              ]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ vars.SLACK_WEBHOOK_URL }}
          SLACK_WEBHOOK_TYPE: INCOMING_WEBHOOK

      - name: Send PagerDuty alert (production only)
        if: ${{ steps.failure.outputs.environment == 'production' && secrets.PAGERDUTY_INTEGRATION_KEY != '' }}
        run: |
          curl -X POST https://events.pagerduty.com/v2/enqueue \
            -H "Content-Type: application/json" \
            -d '{
              "routing_key": "${{ secrets.PAGERDUTY_INTEGRATION_KEY }}",
              "event_action": "trigger",
              "dedup_key": "continuum-deploy-${{ github.run_id }}",
              "payload": {
                "summary": "Production deployment failed for Continuum",
                "severity": "critical",
                "source": "github-actions",
                "custom_details": {
                  "commit": "${{ github.sha }}",
                  "actor": "${{ github.actor }}",
                  "run_url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
                }
              }
            }'
